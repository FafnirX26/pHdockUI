#!/usr/bin/env python3
"""
Create production-optimized PyTorch models based on proven quantum-enhanced ensemble.
Uses the architecture that achieved RÂ² = 0.674 (best performance).
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import pandas as pd
import joblib
from pathlib import Path
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from rdkit import Chem
from rdkit.Chem import Descriptors, AllChem, Fragments
import sys
import warnings
warnings.filterwarnings('ignore')

# Add src to path
sys.path.append('src')
from protonation_engine import ProtonationEngine

# Import the proven quantum descriptor class
class FastQuantumDescriptors:
    """Fast calculation of quantum-inspired descriptors (proven architecture)."""
    
    def __init__(self):
        self.feature_names = []
    
    def calculate_electronic_descriptors(self, mol):
        """Calculate electronic structure descriptors."""
        descriptors = []
        
        try:
            # Partial charges (Gasteiger method - fast)
            AllChem.ComputeGasteigerCharges(mol)
            
            charges = []
            for atom in mol.GetAtoms():
                try:
                    charge = atom.GetDoubleProp('_GasteigerCharge')
                    if not np.isnan(charge) and not np.isinf(charge):
                        charges.append(charge)
                    else:
                        charges.append(0.0)
                except:
                    charges.append(0.0)
            
            if charges:
                descriptors.extend([
                    np.max(charges),              # Most positive charge
                    np.min(charges),              # Most negative charge  
                    np.mean(np.abs(charges)),     # Mean absolute charge
                    np.std(charges),              # Charge distribution
                    np.sum([c for c in charges if c > 0]),  # Total positive charge
                    np.sum([c for c in charges if c < 0]),  # Total negative charge
                ])
            else:
                descriptors.extend([0.0] * 6)
                
        except:
            descriptors.extend([0.0] * 6)
        
        return descriptors
    
    def calculate_frontier_orbital_descriptors(self, mol):
        """Calculate frontier orbital-related descriptors."""
        descriptors = []
        
        try:
            # EState indices (related to HOMO/LUMO energies)
            max_estate = Descriptors.MaxEStateIndex(mol)
            min_estate = Descriptors.MinEStateIndex(mol)
            
            descriptors.extend([
                max_estate,
                min_estate,
                max_estate - min_estate,  # HOMO-LUMO gap proxy
                Descriptors.MaxAbsEStateIndex(mol),
                Descriptors.MaxPartialCharge(mol),
                Descriptors.MinPartialCharge(mol),
                Descriptors.MaxAbsPartialCharge(mol),
            ])
            
        except:
            descriptors.extend([0.0] * 7)
        
        return descriptors
    
    def calculate_polarization_descriptors(self, mol):
        """Calculate polarization and solvation descriptors."""
        descriptors = []
        
        try:
            descriptors.extend([
                Descriptors.MolMR(mol),          # Molar refractivity (polarizability)
                Descriptors.LabuteASA(mol),      # Accessible surface area
                Descriptors.TPSA(mol),           # Topological polar surface area
                Descriptors.VSA_EState1(mol),    # Van der Waals surface area descriptors
                Descriptors.VSA_EState2(mol),
                Descriptors.VSA_EState3(mol),
                Descriptors.VSA_EState4(mol),
                Descriptors.SlogP_VSA1(mol),     # Solvation descriptors
                Descriptors.SlogP_VSA2(mol),
                Descriptors.SMR_VSA1(mol),       # Molar refractivity descriptors
                Descriptors.SMR_VSA2(mol),       # This was top feature!
                Descriptors.SMR_VSA3(mol),
            ])
            
        except:
            descriptors.extend([0.0] * 12)
        
        return descriptors
    
    def calculate_ionization_descriptors(self, mol):
        """Calculate ionization-related descriptors."""
        descriptors = []
        
        try:
            # Basic counts
            descriptors.extend([
                Descriptors.NumHAcceptors(mol),  # Top 3 feature!
                Descriptors.NumHDonors(mol),
                Descriptors.NumHeteroatoms(mol),
                Descriptors.NumRotatableBonds(mol),
            ])
            
            # Functional groups (key for pKa)
            pyridine_count = len(mol.GetSubstructMatches(Chem.MolFromSmarts('c1ccncc1')))
            imidazole_count = len(mol.GetSubstructMatches(Chem.MolFromSmarts('[nH]1cncc1')))
            alcohol_count = len(mol.GetSubstructMatches(Chem.MolFromSmarts('[OH]')))
            carboxyl_count = len(mol.GetSubstructMatches(Chem.MolFromSmarts('[CX3](=O)[OX2H1]')))
            amine_count = len(mol.GetSubstructMatches(Chem.MolFromSmarts('[NX3;H2,H1,H0;!$(NC=O)]')))
            phenol_count = len(mol.GetSubstructMatches(Chem.MolFromSmarts('[OH][c]')))
            
            descriptors.extend([
                pyridine_count,        # Top 2 feature!
                imidazole_count,       # Top 5 feature!
                alcohol_count,         # Top 6 feature!
                carboxyl_count,
                amine_count,
                phenol_count,
            ])
            
        except:
            descriptors.extend([0.0] * 10)
        
        return descriptors
    
    def calculate_aromaticity_descriptors(self, mol):
        """Calculate aromaticity descriptors."""
        descriptors = []
        
        try:
            num_aromatic_rings = Descriptors.NumAromaticRings(mol)
            num_aromatic_hetero = Descriptors.NumAromaticHeterocycles(mol)  # Top 4 feature!
            num_aromatic_carbocycles = Descriptors.NumAromaticCarbocycles(mol)
            
            # Calculate aromatic fraction
            total_atoms = mol.GetNumAtoms()
            aromatic_atoms = sum([atom.GetIsAromatic() for atom in mol.GetAtoms()])
            aromatic_fraction = aromatic_atoms / total_atoms if total_atoms > 0 else 0
            
            descriptors.extend([
                num_aromatic_rings,        # Top 9 feature!
                num_aromatic_hetero,       # Top 4 feature!
                num_aromatic_carbocycles,
                aromatic_fraction,         # Top 10 feature!
                Descriptors.FractionCsp3(mol),
                Descriptors.RingCount(mol),
            ])
            
        except:
            descriptors.extend([0.0] * 6)
        
        return descriptors
    
    def calculate_additional_descriptors(self, mol):
        """Calculate additional molecular descriptors."""
        descriptors = []
        
        try:
            descriptors.extend([
                Descriptors.MolWt(mol),
                Descriptors.MolLogP(mol),
                Descriptors.BalabanJ(mol),
                Descriptors.BertzCT(mol),
                Descriptors.Chi0(mol),
                Descriptors.Chi1(mol),
                Descriptors.Kappa1(mol),
                Descriptors.Kappa2(mol),
                Descriptors.Kappa3(mol),
                Descriptors.HeavyAtomCount(mol),
                Descriptors.VSA_EState8(mol),      # Top 8 feature!
                Descriptors.EState_VSA1(mol),
                Descriptors.EState_VSA2(mol),
                Descriptors.EState_VSA3(mol),
            ])
            
        except:
            descriptors.extend([0.0] * 14)
        
        return descriptors
    
    def extract_features_batch(self, smiles_list):
        """Extract quantum features for a batch of SMILES."""
        features_list = []
        valid_indices = []
        
        for i, smiles in enumerate(smiles_list):
            try:
                mol = Chem.MolFromSmiles(smiles)
                if mol is None:
                    continue
                
                # Extract all quantum descriptor groups
                features = []
                features.extend(self.calculate_electronic_descriptors(mol))        # 6 features
                features.extend(self.calculate_frontier_orbital_descriptors(mol))  # 7 features  
                features.extend(self.calculate_polarization_descriptors(mol))      # 12 features
                features.extend(self.calculate_ionization_descriptors(mol))        # 10 features
                features.extend(self.calculate_aromaticity_descriptors(mol))       # 6 features
                features.extend(self.calculate_additional_descriptors(mol))        # 14 features
                
                # Ensure exactly 55 features
                features = features[:55]
                while len(features) < 55:
                    features.append(0.0)
                
                # Handle invalid values
                features = [x if not np.isnan(x) and not np.isinf(x) else 0.0 for x in features]
                
                features_list.append(features)
                valid_indices.append(i)
                
            except Exception as e:
                continue
        
        return np.array(features_list), valid_indices


class ProductionFeatureExtractor(nn.Module):
    """Production-optimized feature extractor using proven quantum architecture."""
    
    def __init__(self):
        super(ProductionFeatureExtractor, self).__init__()
        
        # Direct quantum descriptor calculation (no neural network needed)
        self.quantum_calculator = FastQuantumDescriptors()
        
    def forward(self, smiles_list):
        """Extract quantum features from SMILES strings."""
        features, valid_indices = self.quantum_calculator.extract_features_batch(smiles_list)
        return torch.tensor(features, dtype=torch.float32), valid_indices
    
    def extract_single(self, smiles):
        """Extract features for a single SMILES."""
        features, _ = self.quantum_calculator.extract_features_batch([smiles])
        if len(features) > 0:
            return torch.tensor(features[0], dtype=torch.float32)
        return torch.zeros(55, dtype=torch.float32)


class ProductionProtonationModel(nn.Module):
    """Production-optimized protonation model using ensemble architecture."""
    
    def __init__(self):
        super(ProductionProtonationModel, self).__init__()
        
        # Load the proven ensemble models
        self.load_proven_models()
        
        # Neural network for additional pH-dependent state prediction
        self.state_predictor = nn.Sequential(
            nn.Linear(56, 128),  # 55 features + pH
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 3)  # neutral, protonated, deprotonated probabilities
        )
        
        self.protonation_engine = ProtonationEngine()
        
    def load_proven_models(self):
        """Load the proven XGBoost and Random Forest models."""
        models_dir = Path("models")
        
        # Load the models that achieved RÂ² = 0.674
        self.xgb_model = joblib.load(models_dir / "fast_quantum_xgb.pkl")
        self.rf_model = joblib.load(models_dir / "fast_quantum_rf.pkl")
        self.scaler = joblib.load(models_dir / "fast_quantum_scaler.pkl")
        self.ensemble_weights = joblib.load(models_dir / "fast_quantum_weights.pkl")
        
    def predict_pka(self, features):
        """Predict pKa using proven ensemble (XGB + RF)."""
        if isinstance(features, torch.Tensor):
            features_np = features.detach().numpy()
        else:
            features_np = np.array(features)
            
        # Ensure proper shape for single prediction
        if features_np.ndim == 1:
            features_np = features_np.reshape(1, -1)
            
        # Scale features
        try:
            features_scaled = self.scaler.transform(features_np)
        except Exception as e:
            print(f"Scaling error: {e}")
            return torch.tensor([0.0], dtype=torch.float32)
        
        # Ensemble prediction (proven weights: XGB=0.75, RF=0.25)
        try:
            xgb_pred = self.xgb_model.predict(features_scaled)
            rf_pred = self.rf_model.predict(features_scaled)
            
            ensemble_pred = self.ensemble_weights[0] * xgb_pred + self.ensemble_weights[1] * rf_pred
            
            # Ensure it's a scalar for single prediction
            if isinstance(ensemble_pred, np.ndarray) and len(ensemble_pred) == 1:
                ensemble_pred = ensemble_pred[0]
            
            return torch.tensor(ensemble_pred, dtype=torch.float32)
            
        except Exception as e:
            print(f"Prediction error: {e}")
            return torch.tensor([0.0], dtype=torch.float32)
        
    def forward(self, features, ph=None):
        """Forward pass through protonation model."""
        # Get pKa prediction from proven ensemble
        pka_pred = self.predict_pka(features)
        
        if ph is not None:
            # Combine features with pH for state prediction
            if isinstance(ph, (int, float)):
                ph = torch.tensor([ph], dtype=torch.float32)
            
            if features.dim() == 1:
                features = features.unsqueeze(0)
            if ph.dim() == 0:
                ph = ph.unsqueeze(0)
                
            # Expand pH to match batch size
            ph_expanded = ph.expand(features.size(0), 1)
            combined_input = torch.cat([features, ph_expanded], dim=1)
            
            # Predict protonation states
            state_logits = self.state_predictor(combined_input)
            state_probs = torch.softmax(state_logits, dim=1)
            
            return pka_pred, state_probs
        
        return pka_pred
    
    def predict_protonation_states(self, smiles, ph_values):
        """Predict protonation states using Henderson-Hasselbalch equation."""
        results = {}
        
        try:
            # Extract features
            feature_extractor = ProductionFeatureExtractor()
            features = feature_extractor.extract_single(smiles)
            
            # Get pKa prediction
            pka_pred = self.predict_pka(features)
            if isinstance(pka_pred, torch.Tensor):
                if pka_pred.numel() == 1:
                    pka_value = float(pka_pred.item())
                else:
                    pka_value = float(pka_pred[0])
            else:
                pka_value = float(pka_pred)
            
            for ph in ph_values:
                # Henderson-Hasselbalch equation: pH = pKa + log([A-]/[HA])
                # Fraction deprotonated = 1 / (1 + 10^(pKa - pH))
                fraction_deprotonated = 1.0 / (1.0 + 10**(pka_value - ph))
                fraction_protonated = 1.0 - fraction_deprotonated
                
                # Use neural network for refined state prediction
                with torch.no_grad():
                    _, state_probs = self.forward(features.unsqueeze(0), torch.tensor([ph]))
                    neural_probs = state_probs[0].numpy()
                
                # Combine Henderson-Hasselbalch with neural network (weighted average)
                hh_weight = 0.7  # Trust H-H equation more for pKa-based prediction
                nn_weight = 0.3
                
                final_neutral = hh_weight * (1.0 - abs(fraction_deprotonated - 0.5)) + nn_weight * neural_probs[0]
                final_protonated = hh_weight * (1.0 - fraction_deprotonated) + nn_weight * neural_probs[1]  
                final_deprotonated = hh_weight * fraction_deprotonated + nn_weight * neural_probs[2]
                
                # Normalize probabilities
                total = final_neutral + final_protonated + final_deprotonated
                if total > 0:
                    final_neutral /= total
                    final_protonated /= total
                    final_deprotonated /= total
                
                results[ph] = {
                    'predicted_pka': pka_value,
                    'neutral_prob': float(final_neutral),
                    'protonated_prob': float(final_protonated), 
                    'deprotonated_prob': float(final_deprotonated),
                    'hh_fraction_deprotonated': fraction_deprotonated
                }
                
        except Exception as e:
            print(f"Error processing protonation states for {smiles}: {e}")
            
        return results


def train_state_predictor(model, training_data, epochs=100):
    """Train only the neural network component for state prediction."""
    print("Training state predictor component...")
    
    feature_extractor = ProductionFeatureExtractor()
    
    X_features = []
    y_states = []
    
    # Generate synthetic training data for state prediction
    for idx, row in training_data.head(5000).iterrows():
        try:
            smiles = row['smiles']
            pka_true = float(row['pka_value'])
            
            features = feature_extractor.extract_single(smiles)
            if features.sum() == 0:  # Skip invalid molecules
                continue
            
            # Generate training data for different pH values
            for ph in [4.0, 7.0, 10.0]:
                # Calculate true state using Henderson-Hasselbalch
                fraction_deprotonated = 1.0 / (1.0 + 10**(pka_true - ph))
                
                # Create ground truth labels based on H-H equation
                if fraction_deprotonated < 0.1:
                    state_label = [1.0, 0.0, 0.0]  # neutral/protonated
                elif fraction_deprotonated > 0.9:
                    state_label = [0.0, 0.0, 1.0]  # deprotonated
                else:
                    # Mixed state - use continuous values
                    neutral_prob = 1.0 - abs(fraction_deprotonated - 0.5)
                    protonated_prob = 1.0 - fraction_deprotonated
                    deprotonated_prob = fraction_deprotonated
                    
                    # Normalize
                    total = neutral_prob + protonated_prob + deprotonated_prob
                    state_label = [neutral_prob/total, protonated_prob/total, deprotonated_prob/total]
                
                # Combine features with pH
                combined_features = torch.cat([features, torch.tensor([ph])])
                X_features.append(combined_features)
                y_states.append(state_label)
                
        except Exception as e:
            continue
    
    if len(X_features) == 0:
        print("No valid training data for state predictor")
        return model
        
    X = torch.stack(X_features)
    y = torch.tensor(y_states, dtype=torch.float32)
    
    print(f"Training state predictor on {len(X)} samples...")
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.state_predictor.parameters(), lr=0.001)
    
    model.train()
    for epoch in range(epochs):
        optimizer.zero_grad()
        
        # Forward pass through state predictor only
        state_logits = model.state_predictor(X)
        loss = criterion(state_logits, y)
        
        loss.backward()
        optimizer.step()
        
        if epoch % 20 == 0:
            print(f"  Epoch {epoch}/{epochs}, Loss: {loss.item():.4f}")
    
    model.eval()
    print("State predictor training completed")
    return model


def validate_models():
    """Validate the models against known test cases."""
    print("\nðŸ”¬ Validating against known compounds...")
    
    feature_extractor = ProductionFeatureExtractor()
    protonation_model = ProductionProtonationModel()
    
    # Test cases with known pKa values
    test_cases = [
        ("CCO", "Ethanol", 15.9),
        ("CC(=O)O", "Acetic acid", 4.76),
        ("c1ccccc1O", "Phenol", 9.95),
        ("CCN", "Ethylamine", 10.7),
        ("c1cccnc1", "Pyridine", 5.2),
        ("CC(C)(C)C(=O)O", "Pivaloic acid", 5.03),
    ]
    
    total_error = 0
    valid_predictions = 0
    
    for smiles, name, known_pka in test_cases:
        try:
            features = feature_extractor.extract_single(smiles)
            predicted_pka = protonation_model.predict_pka(features)
            
            if isinstance(predicted_pka, torch.Tensor):
                if predicted_pka.numel() == 1:
                    pred_value = float(predicted_pka.item())
                else:
                    pred_value = float(predicted_pka[0])
            else:
                pred_value = float(predicted_pka)
            
            error = abs(pred_value - known_pka)
            total_error += error
            valid_predictions += 1
            
            print(f"  {name:15} | Known: {known_pka:5.2f} | Predicted: {pred_value:5.2f} | Error: {error:5.2f}")
            
        except Exception as e:
            print(f"  {name:15} | ERROR: {e}")
    
    if valid_predictions > 0:
        mae = total_error / valid_predictions
        print(f"\nâœ… Validation MAE: {mae:.2f} pKa units")
        return mae < 2.0  # Consider good if MAE < 2.0
    
    return False


def main():
    """Create production-optimized PyTorch models."""
    print("ðŸš€ Creating Production-Optimized PyTorch Models")
    print("="*60)
    
    # Load training data
    print("ðŸ“Š Loading training data...")
    df = pd.read_csv('training_data/filtered_pka_dataset.csv')
    if 'pka_value' in df.columns:
        df['pka'] = df['pka_value']
    print(f"   Loaded {len(df)} training samples")
    
    # Create models directory
    models_dir = Path("models")
    models_dir.mkdir(exist_ok=True)
    
    # Create feature extractor (direct quantum calculation - no training needed)
    print("\n1ï¸âƒ£ Creating Production Feature Extractor...")
    feature_extractor = ProductionFeatureExtractor()
    print("   âœ… Feature extractor ready (using proven quantum descriptors)")
    
    # Create protonation model (loads proven ensemble)
    print("\n2ï¸âƒ£ Creating Production Protonation Model...")
    protonation_model = ProductionProtonationModel()
    
    # Train the neural network component for state prediction
    protonation_model = train_state_predictor(protonation_model, df, epochs=100)
    print("   âœ… Protonation model ready (proven ensemble + trained state predictor)")
    
    # Validate models
    print("\n3ï¸âƒ£ Validating Models...")
    validation_passed = validate_models()
    
    if validation_passed:
        print("   âœ… Validation passed")
    else:
        print("   âš ï¸ Validation issues detected, but proceeding...")
    
    # Save models
    print("\n4ï¸âƒ£ Saving Production Models...")
    
    # Save feature extractor
    feature_extractor_path = models_dir / "production_feature_extractor.pt"
    torch.save({
        'model_state_dict': feature_extractor.state_dict(),
        'model_class': 'ProductionFeatureExtractor',
        'description': 'Production feature extractor using proven 55-feature quantum descriptors (RÂ² = 0.674)',
        'features': 55,
        'architecture': 'Direct quantum calculation (no neural network)',
        'performance': 'RÂ² = 0.674, MAE = 1.209 pKa units'
    }, feature_extractor_path)
    print(f"   âœ… Feature extractor: {feature_extractor_path}")
    
    # Save protonation model
    protonation_model_path = models_dir / "production_protonation_model.pt"
    torch.save({
        'model_state_dict': protonation_model.state_dict(),
        'model_class': 'ProductionProtonationModel', 
        'description': 'Production protonation model using proven XGBoost+RF ensemble + neural state predictor',
        'ensemble_weights': [0.75, 0.25],  # XGB, RF weights
        'architecture': 'Proven ensemble (XGB+RF) + neural network state predictor',
        'performance': 'RÂ² = 0.674, MAE = 1.209 pKa units',
        'ph_range': [1.0, 14.0]
    }, protonation_model_path)
    print(f"   âœ… Protonation model: {protonation_model_path}")
    
    # Test final models
    print("\n5ï¸âƒ£ Testing Final Models...")
    test_smiles = ["CC(=O)O", "c1ccccc1O", "CCN"]
    
    for smiles in test_smiles:
        try:
            features = feature_extractor.extract_single(smiles)
            states = protonation_model.predict_protonation_states(smiles, [4.0, 7.0, 10.0])
            
            print(f"   {smiles}:")
            for ph, info in states.items():
                print(f"     pH {ph}: pKa={info['predicted_pka']:.2f}, "
                      f"States=[N:{info['neutral_prob']:.2f}, "
                      f"P:{info['protonated_prob']:.2f}, "
                      f"D:{info['deprotonated_prob']:.2f}]")
                      
        except Exception as e:
            print(f"   {smiles}: ERROR - {e}")
    
    print(f"\nðŸŽ‰ Production models created successfully!")
    print(f"ðŸ“ Models saved in: {models_dir.absolute()}")
    print(f"   - production_feature_extractor.pt: Proven quantum descriptors")
    print(f"   - production_protonation_model.pt: Ensemble + neural state predictor")
    print(f"\nðŸ“Š Based on architecture achieving RÂ² = 0.674 (best performance)")


if __name__ == "__main__":
    main()